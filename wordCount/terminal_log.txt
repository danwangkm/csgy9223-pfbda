[cloudera@quickstart ~]$ cd homework2
[cloudera@quickstart homework2]$ ls
input.txt  WordCount.java  WordCountMapper.java  WordCountReducer.java
[cloudera@quickstart homework2]$ javac -classpath `yarn classpath` -d . WordCountMapper.java 
[cloudera@quickstart homework2]$ javac -classpath `yarn classpath` -d . WordCountReducer.java 
[cloudera@quickstart homework2]$ javac -classpath `yarn classpath`:. -d . WordCount.java 
Note: WordCount.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
[cloudera@quickstart homework2]$ ls
input.txt        WordCountMapper.class   WordCountReducer.java
WordCount.class  WordCountMapper.java
WordCount.java   WordCountReducer.class
[cloudera@quickstart homework2]$ jar -cvf wordCount.jar *.class
added manifest
adding: WordCount.class(in = 1388) (out= 795)(deflated 42%)
adding: WordCountMapper.class(in = 1744) (out= 752)(deflated 56%)
adding: WordCountReducer.class(in = 1602) (out= 668)(deflated 58%)
[cloudera@quickstart homework2]$ ls
input.txt        wordCount.jar   WordCountMapper.class  WordCountReducer.class
WordCount.class  WordCount.java  WordCountMapper.java   WordCountReducer.java
[cloudera@quickstart homework2]$ hdfs dfs -ls /usr/cloudera
ls: `/usr/cloudera': No such file or directory
[cloudera@quickstart homework2]$ hdfs dfs -ls /user/cloudera
Found 2 items
drwxr-xr-x   - cloudera cloudera          0 2016-09-13 13:59 /user/cloudera/assignment1
drwxr-xr-x   - cloudera cloudera          0 2016-09-13 19:27 /user/cloudera/class1
[cloudera@quickstart homework2]$ hdfs dfs -mkdir /user/cloudera/class2
[cloudera@quickstart homework2]$ hdfs dfs -ls /user/cloudera
Found 3 items
drwxr-xr-x   - cloudera cloudera          0 2016-09-13 13:59 /user/cloudera/assignment1
drwxr-xr-x   - cloudera cloudera          0 2016-09-13 19:27 /user/cloudera/class1
drwxr-xr-x   - cloudera cloudera          0 2016-09-21 19:36 /user/cloudera/class2
[cloudera@quickstart homework2]$ hdfs dfs -put input.txt /user/cloudera/class2
[cloudera@quickstart homework2]$ hdfs dfs -cat /user/cloudera/class2/input.txt
09-Dec-16,5:00PM;#Hackatopia,Tribeca Film Hackathon: Code As A New Language For Content Creators Hackathon
28-Oct-16,7:00PM;#NYCHadoop,Hadoop-NYC Strata/Hadoop World Meetup at AppNexus NYC
31-Dec-16,3:00PM;#Hackatopia,Designers, Developers, Doers, don't miss this upcoming Chicago hackathon[cloudera@quickstart homework2]$ javac -
[cloudera@quickstart homework2]$ hdfs dfs -cat /user/cloudera/class2/input.txt
09-Dec-16,5:00PM;#Hackatopia,Tribeca Film Hackathon: Code As A New Language For Content Creators Hackathon
28-Oct-16,7:00PM;#NYCHadoop,Hadoop-NYC Strata/Hadoop World Meetup at AppNexus NYC
31-Dec-16,3:00PM;#Hackatopia,Designers, Developers, Doers, don't miss this upcoming Chicago hackathon[cloudera@quickstart homework2]$ 
[cloudera@quickstart homework2]$ hadoop jar wordCount.jar WordCount /user/cloudera/class2/input.txt /user/cloudera/class2/output
16/09/21 19:39:08 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/09/21 19:39:09 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/09/21 19:39:09 INFO input.FileInputFormat: Total input paths to process : 1
16/09/21 19:39:10 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:862)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:600)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:789)
16/09/21 19:39:10 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:862)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:600)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:789)
16/09/21 19:39:10 INFO mapreduce.JobSubmitter: number of splits:1
16/09/21 19:39:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1474508752764_0001
16/09/21 19:39:10 INFO impl.YarnClientImpl: Submitted application application_1474508752764_0001
16/09/21 19:39:10 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1474508752764_0001/
16/09/21 19:39:10 INFO mapreduce.Job: Running job: job_1474508752764_0001
16/09/21 19:39:21 INFO mapreduce.Job: Job job_1474508752764_0001 running in uber mode : false
16/09/21 19:39:21 INFO mapreduce.Job:  map 0% reduce 0%
16/09/21 19:39:28 INFO mapreduce.Job:  map 100% reduce 0%
16/09/21 19:39:35 INFO mapreduce.Job:  map 100% reduce 100%
16/09/21 19:39:35 INFO mapreduce.Job: Job job_1474508752764_0001 completed successfully
16/09/21 19:39:35 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=159
		FILE: Number of bytes written=232849
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=417
		HDFS: Number of bytes written=35
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4699
		Total time spent by all reduces in occupied slots (ms)=5342
		Total time spent by all map tasks (ms)=4699
		Total time spent by all reduce tasks (ms)=5342
		Total vcore-seconds taken by all map tasks=4699
		Total vcore-seconds taken by all reduce tasks=5342
		Total megabyte-seconds taken by all map tasks=4811776
		Total megabyte-seconds taken by all reduce tasks=5470208
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=129
		Map output materialized bytes=159
		Input split bytes=127
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=159
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=112
		CPU time spent (ms)=1240
		Physical memory (bytes) snapshot=342937600
		Virtual memory (bytes) snapshot=3006967808
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=290
	File Output Format Counters 
		Bytes Written=35
[cloudera@quickstart homework2]$ hdfs dfs -ls /user/cloudera/class2/outputFound 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-09-21 19:39 /user/cloudera/class2/output/_SUCCESS
-rw-r--r--   1 cloudera cloudera         35 2016-09-21 19:39 /user/cloudera/class2/output/part-r-00000
[cloudera@quickstart homework2]$ hdfs dfs -cat /user/cloudera/class2/output/part-r-00000
Chicago	1
Dec	2
Java	0
hackathon	2
[cloudera@quickstart homework2]$ 

